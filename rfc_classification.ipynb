{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_baseline(X_train, y_train, X_test, y_test):\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    from sklearn.utils import validation\n",
    "    checked_X_test_ = validation.check_array(X_test, accept_sparse=['csr', 'csc', 'coo'])\n",
    "    classes_ = dummy_clf.classes_\n",
    "    class_prior_ = dummy_clf.class_prior_\n",
    "    n_samples = int(checked_X_test_.shape[0])\n",
    "    predicted_y = np.tile([classes_[k][class_prior_[k].argmax()] for k in range(dummy_clf.n_outputs_)], [n_samples, 1])\n",
    "    from sklearn.metrics import classification\n",
    "    return classification.accuracy_score(y_test, predicted_y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_dataset = np.genfromtxt(\"/Users/jane/rfc-analysis/analysis/new_input_features/no_closer_participation/after_closing_excluded/csv/with_ids/classification_features_before_closing.csv\", delimiter=\",\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6474, 39)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_INPUT_INDEX = 1\n",
    "MAX_INPUT_INDEX = 37\n",
    "OUTPUT_INDEX = 38\n",
    "ROW_NUM = 6474\n",
    "COLUMN_NUM = 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_inputs(dataset, input_idx):\n",
    "    total_inputs = []\n",
    "    for row in dataset:\n",
    "        selected_input = [row[id] for id in input_idx]\n",
    "        total_inputs.append(selected_input)\n",
    "    return total_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_output(dataset, output_idx):\n",
    "    return list(row[output_idx] for row in dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_inputs = extract_inputs(rfc_dataset, range(MIN_INPUT_INDEX, MAX_INPUT_INDEX+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_outputs = extract_output(rfc_dataset, OUTPUT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(total_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array(total_outputs).reshape(ROW_NUM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shaped_dataset = [X, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5667953667953668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'comments_count':1, 'participants_count':2, 'sum_participant_edit_count':3, \n",
    "            'avg_participant_edit_count':4,'initiator_edit_count':5, 'initiator_expertise_(days)':6, \n",
    "            'weighted_reciprocity':7, 'avg_reply_num':8, 'avg_reply_depth':9, \n",
    "            'article_word_count':10, 'article_character_count':11, 'rfc_positive':12,\n",
    "            'rfc_negative':13, 'rfc_certain':14, 'rfc_tentative':15, \n",
    "            'rfc_anger':16, 'rfc_swear':17, 'rfc_insight':18, \n",
    "            'rfc_incl':19, 'rfc_hostile':20, 'rfc_i':21, \n",
    "            'rfc_percept':22, 'rfc_excl':23, 'rfc_cogmech':24,\n",
    "            'rfc_affect':25, 'revision_count_before_rfc':26, 'initiator_revision_before_rfc_count':27, \n",
    "            'new_participant_ratio':28, 'one_week_recent_rev_count':29,'two_weeks_recent_rev_count':30,\n",
    "            'three_weeks_recent_rev_count':31, 'one_month_recent_rev_count':32, 'two_months_recent_rev_count':33,\n",
    "            'avg_expertise_except_closer_(days)':34, 'max_expertise_except_closer_(days)':35,\n",
    "            'sd_expertise_except_closer_(days)':36, 'sum_expertise_except_closer_(days)':37\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = sorted(features.iteritems(), key=lambda (k,v): (v,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_weight = {}\n",
    "for i in range(0,50):\n",
    "    X = StandardScaler().fit_transform(total_inputs)\n",
    "    Y = np.array(total_outputs).reshape(ROW_NUM, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "    \n",
    "    dc_clf = DecisionTreeClassifier(max_depth=10)\n",
    "    dc_clf = dc_clf.fit(X_train, y_train)\n",
    "    dc_pred = dc_clf.predict(X_test)\n",
    "    dctree_pd = pd.DataFrame({'feature_importance':dc_clf.feature_importances_},index=feature_names).sort_values('feature_importance', ascending=False)\n",
    "    selected_feature = dctree_pd.to_dict()['feature_importance']\n",
    "    for idx, val in selected_feature.items():\n",
    "        if idx in features_weight:\n",
    "            features_weight[idx] += val\n",
    "        else:\n",
    "            features_weight[idx] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_features_weight = {}\n",
    "for idx, val in features_weight.items():\n",
    "    averaged_features_weight[idx] = val/50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_pdf = pd.DataFrame({'feature_importance':averaged_features_weight},index=averaged_features_weight.keys()).sort_values('feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(participants_count, 2)</th>\n",
       "      <td>0.230349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(max_expertise_except_closer_(days), 35)</th>\n",
       "      <td>0.142956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_reply_num, 8)</th>\n",
       "      <td>0.076621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(comments_count, 1)</th>\n",
       "      <td>0.037983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_reply_depth, 9)</th>\n",
       "      <td>0.037889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_cogmech, 24)</th>\n",
       "      <td>0.036185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_hostile, 20)</th>\n",
       "      <td>0.031508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sum_expertise_except_closer_(days), 37)</th>\n",
       "      <td>0.028648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sd_expertise_except_closer_(days), 36)</th>\n",
       "      <td>0.026957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sum_participant_edit_count, 3)</th>\n",
       "      <td>0.026794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_positive, 12)</th>\n",
       "      <td>0.024320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_affect, 25)</th>\n",
       "      <td>0.023996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_percept, 22)</th>\n",
       "      <td>0.023649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_participant_edit_count, 4)</th>\n",
       "      <td>0.022551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_expertise_except_closer_(days), 34)</th>\n",
       "      <td>0.019199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(revision_count_before_rfc, 26)</th>\n",
       "      <td>0.019080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_incl, 19)</th>\n",
       "      <td>0.016719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_excl, 23)</th>\n",
       "      <td>0.016586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_tentative, 15)</th>\n",
       "      <td>0.016536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(initiator_edit_count, 5)</th>\n",
       "      <td>0.015859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(weighted_reciprocity, 7)</th>\n",
       "      <td>0.015044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(initiator_expertise_(days), 6)</th>\n",
       "      <td>0.013725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_i, 21)</th>\n",
       "      <td>0.013347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_anger, 16)</th>\n",
       "      <td>0.011430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_insight, 18)</th>\n",
       "      <td>0.010781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(new_participant_ratio, 28)</th>\n",
       "      <td>0.010110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_certain, 14)</th>\n",
       "      <td>0.008321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(two_weeks_recent_rev_count, 30)</th>\n",
       "      <td>0.007842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(one_week_recent_rev_count, 29)</th>\n",
       "      <td>0.006230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_negative, 13)</th>\n",
       "      <td>0.005641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_swear, 17)</th>\n",
       "      <td>0.004970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(two_months_recent_rev_count, 33)</th>\n",
       "      <td>0.004611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(article_character_count, 11)</th>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(initiator_revision_before_rfc_count, 27)</th>\n",
       "      <td>0.002645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(article_word_count, 10)</th>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(one_month_recent_rev_count, 32)</th>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(three_weeks_recent_rev_count, 31)</th>\n",
       "      <td>0.001762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           feature_importance\n",
       "(participants_count, 2)                              0.230349\n",
       "(max_expertise_except_closer_(days), 35)             0.142956\n",
       "(avg_reply_num, 8)                                   0.076621\n",
       "(comments_count, 1)                                  0.037983\n",
       "(avg_reply_depth, 9)                                 0.037889\n",
       "(rfc_cogmech, 24)                                    0.036185\n",
       "(rfc_hostile, 20)                                    0.031508\n",
       "(sum_expertise_except_closer_(days), 37)             0.028648\n",
       "(sd_expertise_except_closer_(days), 36)              0.026957\n",
       "(sum_participant_edit_count, 3)                      0.026794\n",
       "(rfc_positive, 12)                                   0.024320\n",
       "(rfc_affect, 25)                                     0.023996\n",
       "(rfc_percept, 22)                                    0.023649\n",
       "(avg_participant_edit_count, 4)                      0.022551\n",
       "(avg_expertise_except_closer_(days), 34)             0.019199\n",
       "(revision_count_before_rfc, 26)                      0.019080\n",
       "(rfc_incl, 19)                                       0.016719\n",
       "(rfc_excl, 23)                                       0.016586\n",
       "(rfc_tentative, 15)                                  0.016536\n",
       "(initiator_edit_count, 5)                            0.015859\n",
       "(weighted_reciprocity, 7)                            0.015044\n",
       "(initiator_expertise_(days), 6)                      0.013725\n",
       "(rfc_i, 21)                                          0.013347\n",
       "(rfc_anger, 16)                                      0.011430\n",
       "(rfc_insight, 18)                                    0.010781\n",
       "(new_participant_ratio, 28)                          0.010110\n",
       "(rfc_certain, 14)                                    0.008321\n",
       "(two_weeks_recent_rev_count, 30)                     0.007842\n",
       "(one_week_recent_rev_count, 29)                      0.006230\n",
       "(rfc_negative, 13)                                   0.005641\n",
       "(rfc_swear, 17)                                      0.004970\n",
       "(two_months_recent_rev_count, 33)                    0.004611\n",
       "(article_character_count, 11)                        0.004103\n",
       "(initiator_revision_before_rfc_count, 27)            0.002645\n",
       "(article_word_count, 10)                             0.002552\n",
       "(one_month_recent_rev_count, 32)                     0.002503\n",
       "(three_weeks_recent_rev_count, 31)                   0.001762"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = feature_importance_pdf[:7].to_dict()['feature_importance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize decision tree with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_index = []\n",
    "chosen_feature_names = []\n",
    "for name, index in selected_features.keys():\n",
    "    chosen_index.append(index)\n",
    "    chosen_feature_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_inputs = extract_inputs(rfc_dataset, chosen_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_outputs = extract_output(rfc_dataset, OUTPUT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_filtered = StandardScaler().fit_transform(filtered_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_filtered = np.array(total_outputs).reshape(6474, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(X_filtered, Y_filtered, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [X_filtered, Y_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_clf_5 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=150)\n",
    "dc_clf_5 = dc_clf_5.fit(X_train_filtered, y_train_filtered)\n",
    "dc_pred_5 = dc_clf_5.predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = [\"unclosed\",\"closed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree_(min-leaf 150 2).pdf'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = export_graphviz(dc_clf_5, out_file=None, filled=True, feature_names=chosen_feature_names, class_names=class_names, rounded=True)\n",
    "graph = graphviz.Source(dd)\n",
    "graph.render('decision_tree_(min-leaf 150 2)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_50_times(classifier, inputs, outputs):\n",
    "    scores = {'accuracy':0.0, 'precision':0.0, 'recall':0.0, 'roc_auc':0.0, 'f1':0.0}\n",
    "    for i in range(50):\n",
    "        X = StandardScaler().fit_transform(inputs)\n",
    "        Y = np.array(outputs).reshape(ROW_NUM, 1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier_pred = classifier.predict(X_test)\n",
    "        scores['accuracy'] += accuracy_score(y_test, classifier_pred)\n",
    "        scores['precision'] += precision_score(y_test, classifier_pred)\n",
    "        scores['recall'] += recall_score(y_test, classifier_pred)\n",
    "        scores['roc_auc'] += roc_auc_score(y_test, classifier_pred)\n",
    "        scores['f1'] += f1_score(y_test, classifier_pred)\n",
    "    for score_type, val in scores.items():\n",
    "        scores[score_type] /= 50\n",
    "    print 'Accuracy: ' + str(scores['accuracy'])\n",
    "    print 'Precision: ' + str(scores['precision'])\n",
    "    print 'Recall: ' + str(scores['recall'])\n",
    "    print 'Roc_auc:' + str(scores['roc_auc'])\n",
    "    print 'F1:' + str(scores['f1'])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scores(scores, name):\n",
    "    return pd.DataFrame({name:scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regession LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jane/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.778378378378\n",
      "Precision: 0.77972465582\n",
      "Recall: 0.848773841962\n",
      "Roc_auc:0.767524175883\n",
      "F1:0.812785388128\n"
     ]
    }
   ],
   "source": [
    "logreg_averaged_scores = test_50_times(logreg, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.778378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.812785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.779725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.848774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.767524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logreg_scores\n",
       "accuracy        0.778378\n",
       "f1              0.812785\n",
       "precision       0.779725\n",
       "recall          0.848774\n",
       "roc_auc         0.767524"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(logreg_averaged_scores, 'logreg_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.759845559846\n",
      "Precision: 0.766708701135\n",
      "Recall: 0.828337874659\n",
      "Roc_auc:0.749284801857\n",
      "F1:0.796332678454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.759846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.796333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.766709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.828338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.749285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logreg_averaged_scores\n",
       "accuracy                 0.759846\n",
       "f1                       0.796333\n",
       "precision                0.766709\n",
       "recall                   0.828338\n",
       "roc_auc                  0.749285"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_avg_scores_on_chosen = test_50_times(logreg, filtered_inputs, filtered_outputs)\n",
    "show_scores(logreg_avg_scores_on_chosen, 'logreg_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ADT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adt = AdaBoostClassifier()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794980694981\n",
      "Precision: 0.798597833015\n",
      "Recall: 0.853542234332\n",
      "Roc_auc:0.785951152817\n",
      "F1:0.825156404346\n"
     ]
    }
   ],
   "source": [
    "adt_averaged_scores = test_50_times(adt, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adt_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.794981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.825156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.798598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.853542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.785951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           adt_averaged_scores\n",
       "accuracy              0.794981\n",
       "f1                    0.825156\n",
       "precision             0.798598\n",
       "recall                0.853542\n",
       "roc_auc               0.785951"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(adt_averaged_scores, 'adt_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784942084942\n",
      "Precision: 0.782043343653\n",
      "Recall: 0.860354223433\n",
      "Roc_auc:0.773314366619\n",
      "F1:0.819331819656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adt_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.784942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.819332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.782043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.860354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.773314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           adt_averaged_scores\n",
       "accuracy              0.784942\n",
       "f1                    0.819332\n",
       "precision             0.782043\n",
       "recall                0.860354\n",
       "roc_auc               0.773314"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adt_avg_scores_on_chosen = test_50_times(adt, filtered_inputs, filtered_outputs)\n",
    "show_scores(adt_avg_scores_on_chosen, 'adt_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jane/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.773822393822\n",
      "Precision: 0.763991131923\n",
      "Recall: 0.869673024523\n",
      "Roc_auc:0.75904328588\n",
      "F1:0.813380884163\n"
     ]
    }
   ],
   "source": [
    "rf_averaged_scores = test_50_times(rf, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.773822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.813381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.763991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.869673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.759043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rf_averaged_scores\n",
       "accuracy             0.773822\n",
       "f1                   0.813381\n",
       "precision            0.763991\n",
       "recall               0.869673\n",
       "roc_auc              0.759043"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(rf_averaged_scores, 'rf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jane/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.785034749035\n",
      "Precision: 0.773146357493\n",
      "Recall: 0.878801089918\n",
      "Roc_auc:0.770577015547\n",
      "F1:0.8225116551\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.785035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.822512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.773146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.878801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.770577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rf_averaged_scores\n",
       "accuracy             0.785035\n",
       "f1                   0.822512\n",
       "precision            0.773146\n",
       "recall               0.878801\n",
       "roc_auc              0.770577"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_avg_scores_on_chosen = test_50_times(rf, filtered_inputs, filtered_outputs)\n",
    "show_scores(rf_avg_scores_on_chosen, 'rf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_2d_range = [1e-2, 1, 1e2]\n",
    "# gamma_2d_range = [1e-1, 1, 1e1]\n",
    "C=1\n",
    "gamma=1e-1\n",
    "svm_rbf = SVC(C=C, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.760231660232\n",
      "Precision: 0.770953294946\n",
      "Recall: 0.820844686649\n",
      "Roc_auc:0.750885801435\n",
      "F1:0.795117123062\n"
     ]
    }
   ],
   "source": [
    "svm_rbf_averaged_scores = test_50_times(svm_rbf,total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_rbf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.795117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.770953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.820845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.750886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           svm_rbf_averaged_scores\n",
       "accuracy                  0.760232\n",
       "f1                        0.795117\n",
       "precision                 0.770953\n",
       "recall                    0.820845\n",
       "roc_auc                   0.750886"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(svm_rbf_averaged_scores, 'svm_rbf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.776061776062\n",
      "Precision: 0.764285714286\n",
      "Recall: 0.874659400545\n",
      "Roc_auc:0.760859112037\n",
      "F1:0.815756035578\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_rbf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.776062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.815756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.764286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.874659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.760859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           svm_rbf_averaged_scores\n",
       "accuracy                  0.776062\n",
       "f1                        0.815756\n",
       "precision                 0.764286\n",
       "recall                    0.874659\n",
       "roc_auc                   0.760859"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_avg_scores_on_chosen = test_50_times(svm_rbf, filtered_inputs, filtered_outputs)\n",
    "show_scores(svm_rbf_avg_scores_on_chosen, 'svm_rbf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_clf = DecisionTreeClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.745088803089\n",
      "Precision: 0.744518367713\n",
      "Recall: 0.837738419619\n",
      "Roc_auc:0.730803256155\n",
      "F1:0.788377667175\n"
     ]
    }
   ],
   "source": [
    "dc_clf_averaged_scores = test_50_times(dc_clf, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_clf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.745089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.788378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.744518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.837738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.730803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dc_clf_averaged_scores\n",
       "accuracy                 0.745089\n",
       "f1                       0.788378\n",
       "precision                0.744518\n",
       "recall                   0.837738\n",
       "roc_auc                  0.730803"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(dc_clf_averaged_scores, 'dc_clf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.748918918919\n",
      "Precision: 0.754030526624\n",
      "Recall: 0.826689373297\n",
      "Roc_auc:0.736927574349\n",
      "F1:0.788687795213\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_clf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.748919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.788688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.754031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.826689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.736928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dc_clf_averaged_scores\n",
       "accuracy                 0.748919\n",
       "f1                       0.788688\n",
       "precision                0.754031\n",
       "recall                   0.826689\n",
       "roc_auc                  0.736928"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_clf_avg_scores_on_chosen = test_50_times(dc_clf, filtered_inputs, filtered_outputs)\n",
    "show_scores(dc_clf_avg_scores_on_chosen, 'dc_clf_averaged_scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import urllib2\n",
    "import datetime\n",
    "from os import walk\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_RFC_ID = re.compile(\"{{rfc.*?}}\", re.I)\n",
    "_RFC_HEADER = re.compile(r\"={2,}?([^=\\t\\n\\r\\f\\v]+?)={2,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_title(diff):\n",
    "    candidates = []\n",
    "    # first find the id\n",
    "    rfcid_search = _RFC_ID.search(diff)\n",
    "    if rfcid_search:\n",
    "        rfcid_start = rfcid_search.start()\n",
    "        # print rfcid_start\n",
    "        # find possible candidates\n",
    "        rfc_header_findall = _RFC_HEADER.finditer(diff)\n",
    "        for m in rfc_header_findall:\n",
    "            #assume that the id always is written after the title\n",
    "            if rfcid_start > m.end():\n",
    "                candidates.append( (rfcid_start - m.end(), m.group(0)) )\n",
    "                # print '%02d-%02d: %s' % (m.start(), m.end(), m.group(0))\n",
    "\n",
    "        candidates.sort(key=lambda t:t[0])\n",
    "#         print candidates\n",
    "    return candidates[0][1] if len(candidates) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_rfc_titles(files, folder_dir, erase_folder_name, content_name, output_file_path):\n",
    "    # content_name is the key name of the content, for example, \"revision_content\"\n",
    "    unextracted_rfcs = set()\n",
    "    title_extracted_blob = {}\n",
    "    fieldnames = ['id', 'title']\n",
    "    \n",
    "    with open(output_file_path, 'wb') as csvfile:\n",
    "        title_csv_writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        title_csv_writer.writeheader()\n",
    "        for file_name in files:\n",
    "            if \".json\" in file_name:\n",
    "                path = folder_dir + file_name\n",
    "                rfc_id = file_name.replace(erase_folder_name, \"\").replace(\".json\", \"\").strip()\n",
    "\n",
    "                with open(path) as file:\n",
    "                    rfc_info = json.load(file)\n",
    "\n",
    "                # content\n",
    "                content = rfc_info[content_name]\n",
    "                title = extract_title(content)\n",
    "                if title is not None:\n",
    "                    title_extracted_blob= {\"id\": rfc_id, \"title\": title.encode(\"utf-8\")}\n",
    "                    title_csv_writer.writerow(title_extracted_blob)\n",
    "                else:\n",
    "                    unextracted_rfcs.add(rfc_id)\n",
    "    \n",
    "    \n",
    "    return unextracted_rfcs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_OUTPUT_FILE_PATH = \"/Users/jane/rfc-analysis/titles/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = \"== Bloody Sunday (1972): Did the Bloody Sunday Inquiry find that all those shot were \\\"unarmed\\\"? ==\\n\\n{{rfctag|hist}}\"\n",
    "t2 = \" \\\"dubious\\\" tag on it, is the opposite of \\\"facilitating discussion\\\". [[User:Quigley|Quigley]] ([[User talk:Quigley|talk]]) 22:07, 11 June 2011 (UTC) \\n:::: Please modify only what you disagree. Don't undo anything irrelevant to Hong Kong or Macau. [http://en.wikipedia.org/w/index.php?title=Template:List_of_Asian_capitals_by_region&dir=prev&offset=20110611084749&limit=20&action=history] <== The multiple reverts were indeed disruptive. [[Special:Contributions/119.236.250.27|119.236.250.27]] ([[User talk:119.236.250.27|talk]]) 22:16, 11 June 2011 (UTC)\\n\\n::: I don't know what banned user are you talking about. If you disagree with the inclusion of Hong Kong and Macau, please proceed to propose to remove them. Don't break the 3RR rule by undoing all my edits (including those unrelated to Hong Kong or Macau) and restoring to your own version while I was working to improve this template. [[Special:Contributions/119.236.250.27|119.236.250.27]] ([[User talk:119.236.250.27|talk]]) 22:09, 11 June 2011 (UTC)\\n\\n== Hong Kong and Macau ==\\n{{rfctag|pol|hist}}\\n{{rfcid|78126B8}}\\nThis section is started to facilitate discussion regarding the inclusion of Hong Kong and Macau. SchmuckyTheCat has made multiple disruptive reverts to undo all my edits, including those unrelated to Hong Kong or Macau, wit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'== Hong Kong and Macau =='"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_title(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep track of ids of revs where titles were unextracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unextracted_rfcs = set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract titles from diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_folder_dir = \"/Users/jane/rfc-analysis/diffs/\"\n",
    "diff_files = []\n",
    "for (dirpath, dirnames, filenames) in walk(diff_folder_dir):\n",
    "    diff_files.extend(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10456"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_unextracted_rfcs = extract_rfc_titles(diff_files, diff_folder_dir, \"diff_added_\", \"diff\", _OUTPUT_FILE_PATH + \"diff_based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_unextracted_rfcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So in total 2157 RfCs' titles were not extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. All RfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the file names\n",
    "_all_rev_folder_dir = \"/Users/jane/rfc-analysis/all_content/\"\n",
    "_all_rev_files = []\n",
    "for (dirpath, dirnames, filenames) in walk(_all_rev_folder_dir):\n",
    "    _all_rev_files.extend(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's only use the ids that are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the ids\n",
    "left_files = set()\n",
    "for id in diff_unextracted_rfcs:\n",
    "#     print id\n",
    "    file_name = \"all_content_\" + str(id) + \".json\"\n",
    "#     print file_name \n",
    "    left_files.add(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(left_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content_unextracted_rfcs = extract_rfc_titles(left_files, _all_rev_folder_dir, \"all_content_\", \"revision_content\", _OUTPUT_FILE_PATH + \"revcontent_based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1217"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_content_unextracted_rfcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The unextracted ones are mostly ones in the Request for Comment pages (discovered through manual work)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

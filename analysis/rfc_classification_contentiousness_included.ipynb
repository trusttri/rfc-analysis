{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_baseline(X_train, y_train, X_test, y_test):\n",
    "    dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy_clf.fit(X_train, y_train)\n",
    "    from sklearn.utils import validation\n",
    "    checked_X_test_ = validation.check_array(X_test, accept_sparse=['csr', 'csc', 'coo'])\n",
    "    classes_ = dummy_clf.classes_\n",
    "    class_prior_ = dummy_clf.class_prior_\n",
    "    n_samples = int(checked_X_test_.shape[0])\n",
    "    predicted_y = np.tile([classes_[k][class_prior_[k].argmax()] for k in range(dummy_clf.n_outputs_)], [n_samples, 1])\n",
    "    from sklearn.metrics import classification\n",
    "    return classification.accuracy_score(y_test, predicted_y, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_dataset = np.genfromtxt(\"/Users/jane/rfc-analysis/analysis/new_input_features/no_closer_participation/after_closing_excluded/csv/with_ids/classification_features_including_contentiousness_before_closing.csv\", delimiter=\",\")[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3257, 40)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_INPUT_INDEX = 1\n",
    "MAX_INPUT_INDEX = 38\n",
    "OUTPUT_INDEX = 39\n",
    "ROW_NUM = 3257\n",
    "COLUMN_NUM = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_inputs(dataset, input_idx):\n",
    "    total_inputs = []\n",
    "    for row in dataset:\n",
    "        selected_input = [row[id] for id in input_idx]\n",
    "        total_inputs.append(selected_input)\n",
    "    return total_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_output(dataset, output_idx):\n",
    "    return list(row[output_idx] for row in dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_inputs = extract_inputs(rfc_dataset, range(MIN_INPUT_INDEX, MAX_INPUT_INDEX+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_outputs = extract_output(rfc_dataset, OUTPUT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(total_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array(total_outputs).reshape(ROW_NUM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shaped_dataset = [X, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73369148119723715"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'comments_count':1, 'participants_count':2, 'sum_participant_edit_count':3, \n",
    "            'avg_participant_edit_count':4,'initiator_edit_count':5, 'initiator_expertise_(days)':6, \n",
    "            'weighted_reciprocity':7, 'avg_reply_num':8, 'avg_reply_depth':9, \n",
    "            'article_word_count':10, 'article_character_count':11, \n",
    "            'contentiousness':12,\n",
    "            'rfc_positive':13,\n",
    "            'rfc_negative':14, 'rfc_certain':15, 'rfc_tentative':16, \n",
    "            'rfc_anger':17, 'rfc_swear':18, 'rfc_insight':19, \n",
    "            'rfc_incl':20, 'rfc_hostile':21, 'rfc_i':22, \n",
    "            'rfc_percept':23, 'rfc_excl':24, 'rfc_cogmech':25,\n",
    "            'rfc_affect':26, 'revision_count_before_rfc':27, 'initiator_revision_before_rfc_count':28, \n",
    "            'new_participant_ratio':29, 'one_week_recent_rev_count':30,'two_weeks_recent_rev_count':31,\n",
    "            'three_weeks_recent_rev_count':32, 'one_month_recent_rev_count':33, 'two_months_recent_rev_count':34,\n",
    "            'avg_expertise_except_closer_(days)':35, 'max_expertise_except_closer_(days)':36,\n",
    "            'sd_expertise_except_closer_(days)':37, 'sum_expertise_except_closer_(days)':38\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = sorted(features.iteritems(), key=lambda (k,v): (v,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_weight = {}\n",
    "for i in range(0,50):\n",
    "    X = StandardScaler().fit_transform(total_inputs)\n",
    "    Y = np.array(total_outputs).reshape(ROW_NUM, 1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "    \n",
    "    dc_clf = DecisionTreeClassifier(max_depth=10)\n",
    "    dc_clf = dc_clf.fit(X_train, y_train)\n",
    "    dc_pred = dc_clf.predict(X_test)\n",
    "    dctree_pd = pd.DataFrame({'feature_importance':dc_clf.feature_importances_},index=feature_names).sort_values('feature_importance', ascending=False)\n",
    "    selected_features = dctree_pd.to_dict()['feature_importance']\n",
    "    for idx, val in selected_features.items():\n",
    "        if idx in features_weight:\n",
    "            features_weight[idx] += val\n",
    "        else:\n",
    "            features_weight[idx] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "averaged_features_weight = {}\n",
    "for idx, val in features_weight.items():\n",
    "    averaged_features_weight[idx] = val/50.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(max_expertise_except_closer_(days), 36)</th>\n",
       "      <td>0.134876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_reply_num, 8)</th>\n",
       "      <td>0.076009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(participants_count, 2)</th>\n",
       "      <td>0.064165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sum_participant_edit_count, 3)</th>\n",
       "      <td>0.058309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_expertise_except_closer_(days), 35)</th>\n",
       "      <td>0.057195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_hostile, 21)</th>\n",
       "      <td>0.047387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(comments_count, 1)</th>\n",
       "      <td>0.043309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_participant_edit_count, 4)</th>\n",
       "      <td>0.043125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_insight, 19)</th>\n",
       "      <td>0.039296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_swear, 18)</th>\n",
       "      <td>0.035081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_cogmech, 25)</th>\n",
       "      <td>0.033669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sum_expertise_except_closer_(days), 38)</th>\n",
       "      <td>0.030648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_tentative, 16)</th>\n",
       "      <td>0.029654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_certain, 15)</th>\n",
       "      <td>0.029188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_negative, 14)</th>\n",
       "      <td>0.024887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_i, 22)</th>\n",
       "      <td>0.023702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(revision_count_before_rfc, 27)</th>\n",
       "      <td>0.023183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_positive, 13)</th>\n",
       "      <td>0.020742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(one_week_recent_rev_count, 30)</th>\n",
       "      <td>0.019746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_percept, 23)</th>\n",
       "      <td>0.017611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_excl, 24)</th>\n",
       "      <td>0.015539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(initiator_expertise_(days), 6)</th>\n",
       "      <td>0.015224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(article_word_count, 10)</th>\n",
       "      <td>0.011979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(sd_expertise_except_closer_(days), 37)</th>\n",
       "      <td>0.011432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(avg_reply_depth, 9)</th>\n",
       "      <td>0.010916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(two_months_recent_rev_count, 34)</th>\n",
       "      <td>0.010206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(one_month_recent_rev_count, 33)</th>\n",
       "      <td>0.009987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_incl, 20)</th>\n",
       "      <td>0.009158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(weighted_reciprocity, 7)</th>\n",
       "      <td>0.008738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(contentiousness, 12)</th>\n",
       "      <td>0.007737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_affect, 26)</th>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(initiator_edit_count, 5)</th>\n",
       "      <td>0.006620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(rfc_anger, 17)</th>\n",
       "      <td>0.006230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(three_weeks_recent_rev_count, 32)</th>\n",
       "      <td>0.004801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(article_character_count, 11)</th>\n",
       "      <td>0.004685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(initiator_revision_before_rfc_count, 28)</th>\n",
       "      <td>0.003428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(two_weeks_recent_rev_count, 31)</th>\n",
       "      <td>0.002218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(new_participant_ratio, 29)</th>\n",
       "      <td>0.002024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           feature_importance\n",
       "(max_expertise_except_closer_(days), 36)             0.134876\n",
       "(avg_reply_num, 8)                                   0.076009\n",
       "(participants_count, 2)                              0.064165\n",
       "(sum_participant_edit_count, 3)                      0.058309\n",
       "(avg_expertise_except_closer_(days), 35)             0.057195\n",
       "(rfc_hostile, 21)                                    0.047387\n",
       "(comments_count, 1)                                  0.043309\n",
       "(avg_participant_edit_count, 4)                      0.043125\n",
       "(rfc_insight, 19)                                    0.039296\n",
       "(rfc_swear, 18)                                      0.035081\n",
       "(rfc_cogmech, 25)                                    0.033669\n",
       "(sum_expertise_except_closer_(days), 38)             0.030648\n",
       "(rfc_tentative, 16)                                  0.029654\n",
       "(rfc_certain, 15)                                    0.029188\n",
       "(rfc_negative, 14)                                   0.024887\n",
       "(rfc_i, 22)                                          0.023702\n",
       "(revision_count_before_rfc, 27)                      0.023183\n",
       "(rfc_positive, 13)                                   0.020742\n",
       "(one_week_recent_rev_count, 30)                      0.019746\n",
       "(rfc_percept, 23)                                    0.017611\n",
       "(rfc_excl, 24)                                       0.015539\n",
       "(initiator_expertise_(days), 6)                      0.015224\n",
       "(article_word_count, 10)                             0.011979\n",
       "(sd_expertise_except_closer_(days), 37)              0.011432\n",
       "(avg_reply_depth, 9)                                 0.010916\n",
       "(two_months_recent_rev_count, 34)                    0.010206\n",
       "(one_month_recent_rev_count, 33)                     0.009987\n",
       "(rfc_incl, 20)                                       0.009158\n",
       "(weighted_reciprocity, 7)                            0.008738\n",
       "(contentiousness, 12)                                0.007737\n",
       "(rfc_affect, 26)                                     0.007298\n",
       "(initiator_edit_count, 5)                            0.006620\n",
       "(rfc_anger, 17)                                      0.006230\n",
       "(three_weeks_recent_rev_count, 32)                   0.004801\n",
       "(article_character_count, 11)                        0.004685\n",
       "(initiator_revision_before_rfc_count, 28)            0.003428\n",
       "(two_weeks_recent_rev_count, 31)                     0.002218\n",
       "(new_participant_ratio, 29)                          0.002024"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'feature_importance':averaged_features_weight},index=averaged_features_weight.keys()).sort_values('feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize decision tree with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chosen_index = []\n",
    "chosen_feature_names = []\n",
    "for name, index in selected_features.keys():\n",
    "    chosen_index.append(index)\n",
    "    chosen_feature_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_inputs = extract_inputs(rfc_dataset, chosen_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_outputs = extract_output(rfc_dataset, OUTPUT_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_filtered = StandardScaler().fit_transform(filtered_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_filtered = np.array(total_outputs).reshape(ROW_NUM, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "X_train_filtered, X_test_filtered, y_train_filtered, y_test_filtered = train_test_split(X_filtered, Y_filtered, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [X_filtered, Y_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_clf_5 = DecisionTreeClassifier(max_depth=5, min_samples_leaf=150)\n",
    "dc_clf_5 = dc_clf_5.fit(X_train_filtered, y_train_filtered)\n",
    "dc_pred_5 = dc_clf_5.predict(X_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = [\"unclosed\",\"closed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree_(contentiousness_chosen).pdf'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = export_graphviz(dc_clf_5, out_file=None, filled=True, feature_names=chosen_feature_names, class_names=class_names, rounded=True)\n",
    "graph = graphviz.Source(dd)\n",
    "graph.render('decision_tree_(contentiousness_chosen)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test out various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_50_times(classifier, inputs, outputs):\n",
    "    scores = {'accuracy':0.0, 'precision':0.0, 'recall':0.0, 'roc_auc':0.0, 'f1':0.0}\n",
    "    for i in range(50):\n",
    "        X = StandardScaler().fit_transform(inputs)\n",
    "        Y = np.array(outputs).reshape(ROW_NUM, 1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=42)\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier_pred = classifier.predict(X_test)\n",
    "        scores['accuracy'] += accuracy_score(y_test, classifier_pred)\n",
    "        scores['precision'] += precision_score(y_test, classifier_pred)\n",
    "        scores['recall'] += recall_score(y_test, classifier_pred)\n",
    "        scores['roc_auc'] += roc_auc_score(y_test, classifier_pred)\n",
    "        scores['f1'] += f1_score(y_test, classifier_pred)\n",
    "    for score_type, val in scores.items():\n",
    "        scores[score_type] /= 50\n",
    "    print 'Accuracy: ' + str(scores['accuracy'])\n",
    "    print 'Precision: ' + str(scores['precision'])\n",
    "    print 'Recall: ' + str(scores['recall'])\n",
    "    print 'Roc_auc:' + str(scores['roc_auc'])\n",
    "    print 'F1:' + str(scores['f1'])\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_scores(scores, name):\n",
    "    return pd.DataFrame({name:scores})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regession LG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jane/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:547: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.761320030698\n",
      "Precision: 0.779705117086\n",
      "Recall: 0.940376569038\n",
      "Roc_auc:0.604194048208\n",
      "F1:0.852536747274\n"
     ]
    }
   ],
   "source": [
    "logreg_averaged_scores = test_50_times(logreg, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.761320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.852537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.779705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.940377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.604194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logreg_scores\n",
       "accuracy        0.761320\n",
       "f1              0.852537\n",
       "precision       0.779705\n",
       "recall          0.940377\n",
       "roc_auc         0.604194"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(logreg_averaged_scores, 'logreg_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.761320030698\n",
      "Precision: 0.779705117086\n",
      "Recall: 0.940376569038\n",
      "Roc_auc:0.604194048208\n",
      "F1:0.852536747274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logreg_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.761320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.852537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.779705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.940377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.604194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           logreg_averaged_scores\n",
       "accuracy                 0.761320\n",
       "f1                       0.852537\n",
       "precision                0.779705\n",
       "recall                   0.940377\n",
       "roc_auc                  0.604194"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_avg_scores_on_chosen = test_50_times(logreg, filtered_inputs, filtered_outputs)\n",
    "show_scores(logreg_avg_scores_on_chosen, 'logreg_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ADT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adt = AdaBoostClassifier()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772570990023\n",
      "Precision: 0.804929422849\n",
      "Recall: 0.910732217573\n",
      "Roc_auc:0.651331526654\n",
      "F1:0.854568413689\n"
     ]
    }
   ],
   "source": [
    "adt_averaged_scores = test_50_times(adt, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adt_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.772571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.854568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.804929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.910732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.651332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           adt_averaged_scores\n",
       "accuracy              0.772571\n",
       "f1                    0.854568\n",
       "precision             0.804929\n",
       "recall                0.910732\n",
       "roc_auc               0.651332"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(adt_averaged_scores, 'adt_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77244819647\n",
      "Precision: 0.804900559316\n",
      "Recall: 0.910564853556\n",
      "Roc_auc:0.651247844646\n",
      "F1:0.854478458623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adt_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.772448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.854478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.804901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.910565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.651248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           adt_averaged_scores\n",
       "accuracy              0.772448\n",
       "f1                    0.854478\n",
       "precision             0.804901\n",
       "recall                0.910565\n",
       "roc_auc               0.651248"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adt_avg_scores_on_chosen = test_50_times(adt, filtered_inputs, filtered_outputs)\n",
    "show_scores(adt_avg_scores_on_chosen, 'adt_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jane/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.764343821949\n",
      "Precision: 0.772314512568\n",
      "Recall: 0.962656903766\n",
      "Roc_auc:0.59031980635\n",
      "F1:0.8570259344\n"
     ]
    }
   ],
   "source": [
    "rf_averaged_scores = test_50_times(rf, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.764344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.857026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.772315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.962657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.590320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rf_averaged_scores\n",
       "accuracy             0.764344\n",
       "f1                   0.857026\n",
       "precision            0.772315\n",
       "recall               0.962657\n",
       "roc_auc              0.590320"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(rf_averaged_scores, 'rf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jane/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76515732924\n",
      "Precision: 0.773013681866\n",
      "Recall: 0.962656903766\n",
      "Roc_auc:0.591847183871\n",
      "F1:0.857450266391\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.765157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.857450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.773014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.962657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.591847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rf_averaged_scores\n",
       "accuracy             0.765157\n",
       "f1                   0.857450\n",
       "precision            0.773014\n",
       "recall               0.962657\n",
       "roc_auc              0.591847"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_avg_scores_on_chosen = test_50_times(rf, filtered_inputs, filtered_outputs)\n",
    "show_scores(rf_avg_scores_on_chosen, 'rf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. SVM-RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# C_2d_range = [1e-2, 1, 1e2]\n",
    "# gamma_2d_range = [1e-1, 1, 1e1]\n",
    "C=1\n",
    "gamma=1e-1\n",
    "svm_rbf = SVC(C=C, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76055257099\n",
      "Precision: 0.765238879736\n",
      "Recall: 0.971757322176\n",
      "Roc_auc:0.57521583688\n",
      "F1:0.856221198157\n"
     ]
    }
   ],
   "source": [
    "svm_rbf_averaged_scores = test_50_times(svm_rbf,total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_rbf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.856221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.765239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.971757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.575216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           svm_rbf_averaged_scores\n",
       "accuracy                  0.760553\n",
       "f1                        0.856221\n",
       "precision                 0.765239\n",
       "recall                    0.971757\n",
       "roc_auc                   0.575216"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(svm_rbf_averaged_scores, 'svm_rbf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76055257099\n",
      "Precision: 0.765238879736\n",
      "Recall: 0.971757322176\n",
      "Roc_auc:0.57521583688\n",
      "F1:0.856221198157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svm_rbf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.760553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.856221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.765239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.971757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.575216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           svm_rbf_averaged_scores\n",
       "accuracy                  0.760553\n",
       "f1                        0.856221\n",
       "precision                 0.765239\n",
       "recall                    0.971757\n",
       "roc_auc                   0.575216"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_avg_scores_on_chosen = test_50_times(svm_rbf, filtered_inputs, filtered_outputs)\n",
    "show_scores(svm_rbf_avg_scores_on_chosen, 'svm_rbf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_clf = DecisionTreeClassifier(max_depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.734013814275\n",
      "Precision: 0.792428768304\n",
      "Recall: 0.863723849372\n",
      "Roc_auc:0.620190454946\n",
      "F1:0.826531993211\n"
     ]
    }
   ],
   "source": [
    "dc_clf_averaged_scores = test_50_times(dc_clf, total_inputs, total_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_clf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.734014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.826532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.792429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.863724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.620190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dc_clf_averaged_scores\n",
       "accuracy                 0.734014\n",
       "f1                       0.826532\n",
       "precision                0.792429\n",
       "recall                   0.863724\n",
       "roc_auc                  0.620190"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_scores(dc_clf_averaged_scores, 'dc_clf_averaged_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### How about filtered ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.733430544896\n",
      "Precision: 0.792121174648\n",
      "Recall: 0.863221757322\n",
      "Roc_auc:0.619535950707\n",
      "F1:0.826131934996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dc_clf_averaged_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.733431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.826132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.792121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.863222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.619536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dc_clf_averaged_scores\n",
       "accuracy                 0.733431\n",
       "f1                       0.826132\n",
       "precision                0.792121\n",
       "recall                   0.863222\n",
       "roc_auc                  0.619536"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_clf_avg_scores_on_chosen = test_50_times(dc_clf, filtered_inputs, filtered_outputs)\n",
    "show_scores(dc_clf_avg_scores_on_chosen, 'dc_clf_averaged_scores')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
